{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "def output_label(label):\n",
    "    output_mapping = {\n",
    "                0: \"T-shirt/Top\",\n",
    "                1: \"Trouser\",\n",
    "                2: \"Pullover\",\n",
    "                3: \"Dress\",\n",
    "                4: \"Coat\", \n",
    "                5: \"Sandal\", \n",
    "                6: \"Shirt\",\n",
    "                7: \"Sneaker\",\n",
    "                8: \"Bag\",\n",
    "                9: \"Ankle Boot\"\n",
    "                }\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "class FashionCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "    \n",
    "        self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=64, kernel_size=2),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    )\n",
    "        self.drop1 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2),\n",
    "        nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.drop2 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2),\n",
    "        nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.drop3 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2),\n",
    "        nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        self.drop4 = nn.Dropout2d(0.25)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64, out_features=10)\n",
    "        self.soft=nn.Softmax()\n",
    "        self.drop5 = nn.Dropout2d(0.25)\n",
    "        #self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        # self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.drop1(out)/search\n",
    "        out = self.layer2(out)\n",
    "        out = self.drop2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.drop3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.drop4(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.soft(out)\n",
    "        out = self.drop5(out)\n",
    "        #out = self.fc2(out)\n",
    "        # out = self.fc3(out)\n",
    "        \n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop1): Dropout2d(p=0.25, inplace=False)\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop2): Dropout2d(p=0.25, inplace=False)\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (drop3): Dropout2d(p=0.25, inplace=False)\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (drop4): Dropout2d(p=0.25, inplace=False)\n",
      "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (soft): Softmax(dim=None)\n",
      "  (drop5): Dropout2d(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# plt.imshow(trainset[0].numpy().squeeze(), cmap='gray_r');  \n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 50\n",
    "# count = 0\n",
    "# # Lists for visualization of loss and accuracy \n",
    "# loss_list = []\n",
    "# iteration_list = []\n",
    "# accuracy_list = []\n",
    "\n",
    "# # Lists for knowing classwise accuracy\n",
    "# predictions_list = []\n",
    "# labels_list = []\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for images, labels in trainloader:\n",
    "#         # Transfering images and labels to GPU if available\n",
    "#         images, labels = images.to(device), labels.to(device)        \n",
    "#         # Forward pass \n",
    "#         outputs = model(images)\n",
    "#         loss = error(outputs, labels)\n",
    "        \n",
    "#         # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         #Propagating the error backward\n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Optimizing the parameters\n",
    "#         optimizer.step()\n",
    "    \n",
    "#         count += 1\n",
    "#         # Testing the model\n",
    "    \n",
    "#         if not (count % 50):    # It's same as \"if count % 50 == 0\"\n",
    "#             total = 0\n",
    "#             correct = 0\n",
    "        \n",
    "#             for images, labels in testloader:\n",
    "#                 images, labels = images.to(device), labels.to(device)\n",
    "#                 labels_list.append(labels)\n",
    "            \n",
    "#                 outputs = model(images)\n",
    "            \n",
    "#                 predictions = torch.max(outputs, 1)[1].to(device)\n",
    "#                 predictions_list.append(predictions)\n",
    "#                 correct += (predictions == labels).sum()\n",
    "            \n",
    "#                 total += len(labels)\n",
    "            \n",
    "#             accuracy = correct * 100 / total\n",
    "#             loss_list.append(loss.data)\n",
    "#             iteration_list.append(count)\n",
    "#             accuracy_list.append(accuracy)\n",
    "        \n",
    "#         if not (count % 500):\n",
    "#             print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model\n",
    "criterion = error\n",
    "data_loader = {\n",
    "    \"train\": trainloader,\n",
    "    \"val\": testloader,\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    \"train\": len(trainset),\n",
    "    \"val\": len(testset)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_curve(current_epoch, optimizer_name, loss_name, res):\n",
    "#     x_epoch = list(range(current_epoch))\n",
    "#     loss_train = res[\"loss_train\"]\n",
    "#     loss_val = res[\"loss_val\"]\n",
    "#     plt.plot(x_epoch, loss_train, 'bo-', label='train')\n",
    "#     plt.plot(x_epoch, loss_val, 'ro-', label='val')\n",
    "\n",
    "#     if current_epoch == 0:\n",
    "#         plt.legend()\n",
    "#     os.makedirs(\"loss_graphs\", exist_ok=True)\n",
    "#     plt.savefig(os.path.join('./loss_graphs',\n",
    "#                 f'train_{optimizer_name}_{loss_name}.jpg'))\n",
    "\n",
    "# def train(epochs=100):\n",
    "#     path = \"model\"\n",
    "#     os.makedirs(path, exist_ok=True)\n",
    "#     state_file_name = f\"{path}/state-{net._get_name()}.pth\"\n",
    "#     state_res = {}\n",
    "\n",
    "#     if os.path.exists(state_file_name):\n",
    "#         print(\"files name\")\n",
    "#         state = torch.load(state_file_name)\n",
    "#         net.load_state_dict(state[\"state_dict\"])\n",
    "#         optimizer.load_state_dict(state[\"optimizer\"])\n",
    "#         state_res = state[\"res\"]\n",
    "\n",
    "#     else:\n",
    "#         print(\"Not file\")\n",
    "#     res = {\n",
    "#         \"loss_train\": state_res.get(\"loss_train\", []),\n",
    "#         \"loss_val\": state_res.get(\"loss_val\", []),\n",
    "#         \"epoch\": state_res.get(\"epoch\", 0),\n",
    "#     }\n",
    "#     res[\"epoch\"]\n",
    "\n",
    "#     for epoch in range(res[\"epoch\"]+1, epochs):  # loop over the dataset multiple times\n",
    "#         running_loss = 0.0\n",
    "#         phase_loss = 0\n",
    "#         for phase in [\"train\", \"val\"]:\n",
    "#             if phase == \"train\":\n",
    "#                 net.train(True)  # Set model to training mode\n",
    "#             else:\n",
    "#                 net.train(False)  # Set model to evaluate mode\n",
    "#             for i, data in enumerate(data_loader[phase], 0):\n",
    "#                 # get the inputs; data is a list of [inputs, labels]\n",
    "#                 inputs, labels = data\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "#                 now_batch_size = labels.size()[0]\n",
    "#                 # zero the parameter gradients\n",
    "#                 optimizer.zero_grad()\n",
    "#                 # forward + backward + optimize\n",
    "#                 outputs = net(inputs)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 if phase == \"train\":\n",
    "#                     loss.backward()\n",
    "#                     optimizer.step()\n",
    "#                 # print statistics\n",
    "#                 phase_loss += loss.item() * now_batch_size\n",
    "#                 running_loss += loss.item()\n",
    "#                 if i % 200 == 199 and phase == \"train\":\n",
    "#                     print(\n",
    "#                         f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.4f}')\n",
    "#                     running_loss = 0.0\n",
    "#             phase_loss = phase_loss / dataset_sizes[phase]\n",
    "#             # y_loss[phase].append(phase_loss)\n",
    "#             res[f\"loss_{phase}\"].append(phase_loss)\n",
    "#             res[\"epoch\"] = epoch\n",
    "#         print(\n",
    "#             f\"Epoch {epoch + 1} loss: {res['loss_train'][-1]:.8f} val: {res['loss_val'][-1]:.8f}\")\n",
    "#         draw_curve(epoch, optimizer_name=optimizer.__class__.__name__,\n",
    "#                    loss_name=criterion.__class__.__name__, res=res)\n",
    "\n",
    "#         state = {\n",
    "#             \"epoch\": epoch,\n",
    "#             \"state_dict\": net.state_dict(),\n",
    "#             \"optimizer\": optimizer.state_dict(),\n",
    "#             \"res\": res\n",
    "#         }\n",
    "#         torch.save(state, state_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_curve(current_epoch, optimizer_name, loss_name, res):\n",
    "    x_epoch = list(range(current_epoch))\n",
    "    loss_train = res[\"loss_train\"]\n",
    "    loss_val = res[\"loss_val\"]\n",
    "    plt.plot(x_epoch, loss_train, 'bo-', label='train')\n",
    "    plt.plot(x_epoch, loss_val, 'ro-', label='val')\n",
    "\n",
    "    if current_epoch == 0:\n",
    "        plt.legend()\n",
    "    os.makedirs(\"loss_graphs\", exist_ok=True)\n",
    "    plt.savefig(os.path.join('./loss_graphs',\n",
    "                f'train_{optimizer_name}_{loss_name}.jpg'))\n",
    "\n",
    "def train(epochs=20):\n",
    "    path = \"model\"\n",
    "    state_file_name = f\"{path}/state-{net._get_name()}.pth\"\n",
    "    state_res = {}\n",
    "\n",
    "    print(state_file_name, end=\" \")\n",
    "    if os.path.exists(state_file_name):\n",
    "        print(\"exist\")\n",
    "        state = torch.load(state_file_name)\n",
    "        net.load_state_dict(state[\"state_dict\"])\n",
    "        optimizer.load_state_dict(state[\"optimizer\"])\n",
    "        state_res = state[\"res\"]\n",
    "\n",
    "    else:\n",
    "        print(\"Not exist\")\n",
    "    res = {\n",
    "        \"loss_train\": state_res.get(\"loss_train\", []),\n",
    "        \"loss_val\": state_res.get(\"loss_val\", []),\n",
    "        \"epoch\": state_res.get(\"epoch\", 0),\n",
    "    }\n",
    "    res[\"epoch\"]\n",
    "\n",
    "    # loop over the dataset multiple times\n",
    "    for epoch in range(res[\"epoch\"]+1, epochs):\n",
    "        running_loss = 0.0\n",
    "        phase_loss = 0\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                net.train(False)  # Set model to evaluate mode\n",
    "            for i, data in enumerate(data_loader[phase], 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                now_batch_size = labels.size()[0]\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # print statistics\n",
    "                phase_loss += loss.item() * now_batch_size\n",
    "                running_loss += loss.item()\n",
    "                if i % 200 == 199 and phase == \"train\":\n",
    "                    print(\n",
    "                        f'[{epoch}, {i + 1:5d}] loss: {running_loss / 2000:.4f}')\n",
    "                    running_loss = 0.0\n",
    "            phase_loss = phase_loss / dataset_sizes[phase]\n",
    "            # y_loss[phase].append(phase_loss)\n",
    "            res[f\"loss_{phase}\"].append(phase_loss)\n",
    "            res[\"epoch\"] = epoch\n",
    "        print(\n",
    "            f\"Epoch {epoch} loss: {res['loss_train'][-1]:.8f} val: {res['loss_val'][-1]:.8f}\")\n",
    "        draw_curve(epoch, optimizer_name=optimizer.__class__.__name__,\n",
    "                   loss_name=criterion.__class__.__name__, res=res)\n",
    "\n",
    "        state = {\n",
    "            \"epoch\": epoch,\n",
    "            \"state_dict\": net.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"res\": res\n",
    "        }\n",
    "        torch.save(state, state_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/state-FashionCNN.pth exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_452766/3359979482.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.soft(out)\n",
      "/home/amir/uni/venv/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55,   200] loss: 0.1596\n",
      "[55,   400] loss: 0.1596\n",
      "Epoch 55 loss: 1.59655378 val: 1.56664680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_452766/3359979482.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.soft(out)\n",
      "/home/amir/uni/venv/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56,   200] loss: 0.1601\n",
      "[56,   400] loss: 0.1597\n",
      "Epoch 56 loss: 1.59809034 val: 1.56457340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_452766/3359979482.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.soft(out)\n",
      "/home/amir/uni/venv/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57,   200] loss: 0.1599\n",
      "[57,   400] loss: 0.1593\n",
      "Epoch 57 loss: 1.59443024 val: 1.56479928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_452766/3359979482.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.soft(out)\n",
      "/home/amir/uni/venv/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58,   200] loss: 0.1596\n",
      "[58,   400] loss: 0.1594\n",
      "Epoch 58 loss: 1.59501035 val: 1.56331291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_452766/3359979482.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.soft(out)\n",
      "/home/amir/uni/venv/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59,   200] loss: 0.1599\n",
      "[59,   400] loss: 0.1595\n",
      "Epoch 59 loss: 1.59764017 val: 1.56468999\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_452766/3359979482.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.soft(out)\n",
      "/home/amir/uni/venv/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      1000\n",
      "           1       0.99      0.97      0.98      1000\n",
      "           2       0.82      0.88      0.85      1000\n",
      "           3       0.89      0.90      0.90      1000\n",
      "           4       0.83      0.83      0.83      1000\n",
      "           5       0.98      0.96      0.97      1000\n",
      "           6       0.72      0.68      0.70      1000\n",
      "           7       0.93      0.97      0.95      1000\n",
      "           8       0.97      0.97      0.97      1000\n",
      "           9       0.96      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "f1 0.8957035794993379\n",
      "pre 0.8959052273263224\n",
      "acc 0.896\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# net = FashionCNN().to(device)\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        for a, b in zip(labels, predicted):\n",
    "            # print(a.item(), b.item())\n",
    "            y_true.append(a.item())\n",
    "            y_pred.append(b.item())\n",
    "        # break\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        # _, predicted = torch.max(outputs.data, 1)\n",
    "        # total += labels.size(0)\n",
    "        # correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "print(\"f1\", f1_score(y_true, y_pred, average=\"macro\"))\n",
    "# %%\n",
    "print(\"pre\", precision_score(y_true, y_pred, average=\"macro\"))\n",
    "# %%\n",
    "print(\"acc\", accuracy_score(y_true, y_pred))\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "375aa2ef0b269be7ab695ea0a4cd456f8c66fb0a772baa2b80308fc61f48a1f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
